{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculateCartesianCoordinates(coordinate):\n",
    "    radius, azimuth = coordinate[0], coordinate[1]\n",
    "    return np.array([radius * math.sin(math.radians(azimuth)), radius * math.cos(math.radians(azimuth)), 0])\n",
    "\n",
    "def convertToCartesian(coordinates):\n",
    "    return np.array(list(map(calculateCartesianCoordinates, coordinates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import yaml\n",
    "try:\n",
    "    from yaml import CLoader as Loader\n",
    "except ImportError:\n",
    "    from yaml import Loader\n",
    "\n",
    "import gzip\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "# Reading yml.gz data\n",
    "\n",
    "# Сhange this to where data is stored\n",
    "data_dir = '/Users/bulatgaliev/GitHub/Masters_diploma/radar_calib_data'\n",
    "#'/prun/mipt/student_nirs/2018/galiev_bulat/radar_calib_data'\n",
    "\n",
    "\n",
    "def ungzip(yaml_in_directory):\n",
    "    # наши ямлы требуют небольшой ректификации перед использованием\n",
    "    ungzipped = gzip.open(yaml_in_directory, 'rt')\n",
    "    ungzipped.readline()\n",
    "    ungzipped = ungzipped.read()\n",
    "    ungzipped = ungzipped.replace(':', ': ')\n",
    "\n",
    "    # собственно парсинг\n",
    "    yml = yaml.load(ungzipped, Loader=Loader)\n",
    "    return yml\n",
    "\n",
    "def read_image_grabmsecs(yml_path):\n",
    "    yml_data = ungzip(yml_path)\n",
    "    image_frames = [sh['leftImage']\n",
    "                    for sh in yml_data['shots'] if 'leftImage' in sh.keys()]\n",
    "    \n",
    "    data = np.zeros(shape=(len(image_frames), 1), dtype=int)\n",
    "    i_real = 0\n",
    "    for i_fr in image_frames:\n",
    "        data[i_real, 0] = int(i_fr['grabMsec'])\n",
    "        i_real += 1\n",
    "\n",
    "    data = data[:i_real, :]\n",
    "    return data\n",
    "\n",
    "grabmsecs = np.concatenate((read_image_grabmsecs(os.path.join(data_dir, 't24.305.026.info.yml.gz')).flatten(),\n",
    "                      read_image_grabmsecs(os.path.join(data_dir, 't24.305.027.info.yml.gz')).flatten(),\n",
    "                      read_image_grabmsecs(os.path.join(data_dir, 't24.305.028.info.yml.gz')).flatten(),\n",
    "                      read_image_grabmsecs(os.path.join(data_dir, 't24.305.029.info.yml.gz')).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "# Reading yml data\n",
    "\n",
    "# Сhange this to where data is stored\n",
    "camera_path = os.path.join(data_dir, 'calibs', 'camera.yml')\n",
    "\n",
    "try:\n",
    "    from yaml import CLoader as Loader\n",
    "except ImportError:\n",
    "    from yaml import Loader\n",
    "    \n",
    "def read_yml(yml_path):\n",
    "    yml = yaml.load(yml_path, Loader=Loader)\n",
    "    return yml\n",
    "\n",
    "def opencv_matrix(loader, node):\n",
    "    mapping = loader.construct_mapping(node, deep=True)\n",
    "    dt = np.dtype(mapping[\"dt\"])\n",
    "    mat = np.array(mapping[\"data\"], dt)\n",
    "    mat.resize(mapping[\"rows\"], mapping[\"cols\"])\n",
    "    return mat\n",
    "\n",
    "stream = open(camera_path, 'r')\n",
    "stream.readline()\n",
    "stream = stream.read()\n",
    "stream = stream.replace(':', ': ')\n",
    "yaml.add_constructor(u\"tag:yaml.org,2002:opencv-matrix\", opencv_matrix)\n",
    "data = yaml.load(stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  [[1.39022723e+03 0.00000000e+00 9.62339056e+02]\n",
      " [0.00000000e+00 1.39022723e+03 5.31100969e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "r =  [ 0.04163906 -0.02612186 -0.02203633]\n",
      "t =  [ 0.15882312 -1.58        1.25712767]\n",
      "Image size =  (1920, 1080)\n"
     ]
    }
   ],
   "source": [
    "# Creating Camera object for central projection \n",
    "\n",
    "class Camera:\n",
    "    '''Pinhole camera projection'''\n",
    "    def __init__(self, r, t, K, size):\n",
    "        if  not (t.shape == (3,) and r.shape == (3,) and K.shape == (3,3)):\n",
    "            raise ValueError('bad constructor args')\n",
    "        self.r = r\n",
    "        self.t = t\n",
    "        self.K = K\n",
    "        self.size = size\n",
    "        R = rot_matrix(r)\n",
    "        self.P = K.dot(np.hstack([R, t.reshape(t.shape[0], 1)]))\n",
    "        pass\n",
    "    \n",
    "    def translate(self, points, t):\n",
    "        return np.array([point + t for point in points])\n",
    "    \n",
    "    def rotate(self, points, rot_mat):\n",
    "        return np.array([rot_mat.dot(point) for point in points])\n",
    "    \n",
    "    def transform(self, points):\n",
    "        return self.rotate(points, rot_matrix([np.pi / 2.0, 0, 0]))\n",
    "    \n",
    "    def project(self, points):\n",
    "        if points.shape[1] == 3:\n",
    "            R = rot_matrix(r)\n",
    "            translated = self.translate(points, self.t)\n",
    "#             print(\"Translated: \", translated)\n",
    "            rotated = self.rotate(translated, R.T)\n",
    "#             print(\"Rotated: \", rotated)\n",
    "            tranformed = self.transform(rotated)\n",
    "#             print(\"Transformed: \", tranformed)\n",
    "            homo_pts = self.K.dot(tranformed.T).T\n",
    "#             print(\"homo_pts: \", homo_pts)\n",
    "        elif points.shape[1] == 4:\n",
    "            homo_pts = self.P.dot(points.T)\n",
    "        else:\n",
    "            raise ValueError('Incorrect points size for Camera.project: %s' % \\\n",
    "                             str(points.shape))\n",
    "        return homo_pts[:, : 2] / homo_pts[:, 2].reshape(-1, 1)\n",
    "    \n",
    "def rot_matrix(angles):\n",
    "    cos = [np.math.cos(a) for a in angles]\n",
    "    sin = [np.math.sin(a) for a in angles]\n",
    "    Rz = np.array([[cos[2], -sin[2], 0],\n",
    "                   [sin[2], cos[2],  0],\n",
    "                   [     0,      0,  1]])\n",
    "\n",
    "    Ry = np.array([[ cos[1], 0, sin[1]],\n",
    "                   [      0, 1,      0],\n",
    "                   [-sin[1], 0, cos[1]]])\n",
    "\n",
    "    Rx = np.array([[1,      0,       0],\n",
    "                   [0, cos[0], -sin[0]],\n",
    "                   [0, sin[0], cos[0]]])\n",
    "    #Rs = [Rx, Ry, Rz]\n",
    "    return Ry.dot(Rx).dot(Rz)\n",
    "    \n",
    "K = data[\"K\"]\n",
    "r = data[\"r\"].flatten()\n",
    "t = data[\"t\"].flatten()\n",
    "img_size = (data[\"sz\"][0], data[\"sz\"][1])\n",
    "print('K = ', K)\n",
    "print('r = ', r)\n",
    "print('t = ', t)\n",
    "print('Image size = ', img_size)\n",
    "cam = Camera(r=r, t=-t, K=K, size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frange(x, y, jump):\n",
    "    while x < y:\n",
    "        yield round(x, 1)\n",
    "        x += jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartesianGridPoints = []\n",
    "for x in frange(-10, 10, 0.2):\n",
    "    if float(x).is_integer():\n",
    "        for y in frange(0, 10, 0.2):\n",
    "            cartesianGridPoints.append([x, y, 0])\n",
    "    else:\n",
    "        for y in frange(0, 10, 1):\n",
    "            cartesianGridPoints.append([x, y, 0])\n",
    "gridPoints = cam.project(np.array(cartesianGridPoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#  ICP parameters\n",
    "EPS = 0.0001\n",
    "MAXITER = 100\n",
    "\n",
    "show_animation = True\n",
    "\n",
    "\n",
    "def ICP_matching(ppoints, cpoints):\n",
    "    \"\"\"\n",
    "    Iterative Closest Point matching\n",
    "    - input\n",
    "    ppoints: 2D points in the previous frame\n",
    "    cpoints: 2D points in the current frame\n",
    "    - output\n",
    "    R: Rotation matrix\n",
    "    T: Translation vector\n",
    "    \"\"\"\n",
    "    H = None  # homogeneraous transformation matrix\n",
    "\n",
    "    dError = 1000.0\n",
    "    preError = 1000.0\n",
    "    count = 0\n",
    "\n",
    "    while dError >= EPS:\n",
    "        count += 1\n",
    "\n",
    "        if show_animation:\n",
    "            plt.cla()\n",
    "            plt.plot(ppoints[0, :], ppoints[1, :], \".r\")\n",
    "            plt.plot(cpoints[0, :], cpoints[1, :], \".b\")\n",
    "            plt.plot(0.0, 0.0, \"xr\")\n",
    "            plt.axis(\"equal\")\n",
    "            plt.pause(1.0)\n",
    "\n",
    "        inds, error = nearest_neighbor_assosiation(ppoints, cpoints)\n",
    "        Rt, Tt = SVD_motion_estimation(ppoints[:, inds], cpoints)\n",
    "\n",
    "        # update current points\n",
    "        cpoints = (Rt * cpoints) + Tt\n",
    "\n",
    "        H = update_homogenerous_matrix(H, Rt, Tt)\n",
    "\n",
    "        dError = abs(preError - error)\n",
    "        preError = error\n",
    "        print(\"Residual:\", error)\n",
    "\n",
    "        if dError <= EPS:\n",
    "            print(\"Converge\", error, dError, count)\n",
    "            break\n",
    "        elif MAXITER <= count:\n",
    "            print(\"Not Converge...\", error, dError, count)\n",
    "            break\n",
    "    \n",
    "    R = np.matrix(H[0:2, 0:2])\n",
    "    T = np.matrix(H[0:2, 2])\n",
    "\n",
    "    return R, T, np.array(cpoints.T)\n",
    "\n",
    "\n",
    "def update_homogenerous_matrix(Hin, R, T):\n",
    "\n",
    "    H = np.matrix(np.zeros((3, 3)))\n",
    "\n",
    "    H[0, 0] = R[0, 0]\n",
    "    H[1, 0] = R[1, 0]\n",
    "    H[0, 1] = R[0, 1]\n",
    "    H[1, 1] = R[1, 1]\n",
    "    H[2, 2] = 1.0\n",
    "\n",
    "    H[0, 2] = T[0, 0]\n",
    "    H[1, 2] = T[1, 0]\n",
    "\n",
    "    if Hin is None:\n",
    "        return H\n",
    "    else:\n",
    "        return Hin * H\n",
    "\n",
    "\n",
    "def nearest_neighbor_assosiation(ppoints, cpoints):\n",
    "\n",
    "    # calc the sum of residual errors\n",
    "    dcpoints = ppoints - cpoints\n",
    "    d = np.linalg.norm(dcpoints, axis=0)\n",
    "    error = sum(d)\n",
    "\n",
    "    # calc index with nearest neighbor assosiation\n",
    "    inds = []\n",
    "    for i in range(cpoints.shape[1]):\n",
    "        minid = -1\n",
    "        mind = float(\"inf\")\n",
    "        for ii in range(ppoints.shape[1]):\n",
    "            d = np.linalg.norm(ppoints[:, ii] - cpoints[:, i])\n",
    "\n",
    "            if mind >= d:\n",
    "                mind = d\n",
    "                minid = ii\n",
    "\n",
    "        inds.append(minid)\n",
    "\n",
    "    return inds, error\n",
    "\n",
    "\n",
    "def SVD_motion_estimation(ppoints, cpoints):\n",
    "    pm = np.matrix(np.mean(ppoints, axis=1))\n",
    "    cm = np.matrix(np.mean(cpoints, axis=1))\n",
    "    print(pm)\n",
    "    print(ppoints)\n",
    "    pshift = np.matrix(ppoints - pm)\n",
    "    cshift = np.matrix(cpoints - cm)\n",
    "\n",
    "    W = cshift * pshift.T\n",
    "    u, s, vh = np.linalg.svd(W)\n",
    "\n",
    "    R = (u * vh).T\n",
    "    t = pm - R * cm\n",
    "\n",
    "    return R, t\n",
    "\n",
    "def isRotationMatrix(R) :\n",
    "    Rt = np.transpose(R)\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype = R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    return n < 1e-6\n",
    "\n",
    "def rotationMatrixToEulerAngles(R) :\n",
    " \n",
    "    assert(isRotationMatrix(R))\n",
    "     \n",
    "    sy = math.sqrt(R[0,0] * R[0,0] +  R[1,0] * R[1,0])\n",
    "     \n",
    "    singular = sy < 1e-6\n",
    " \n",
    "    if  not singular :\n",
    "        x = math.atan2(R[2,1] , R[2,2])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = math.atan2(R[1,0], R[0,0])\n",
    "    else :\n",
    "        x = math.atan2(-R[1,2], R[1,1])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = 0\n",
    " \n",
    "    return np.array([x, y, z])\n",
    "\n",
    "def setupNewRT(RTwot, tTwot):\n",
    "    Tr = rot_matrix([np.pi / 2.0, 0, 0])\n",
    "    ROne = rot_matrix(cam.r)\n",
    "    tOne = cam.t\n",
    "    K = cam.K\n",
    "    Rresult = ROne*(np.linalg.inv(Tr)*RTwot*Tr).transpose()\n",
    "    tresult = tOne + np.linalg.inv(RTwot*Tr*ROne.transpose())*(np.linalg.inv(K)*tTwot.transpose()).transpose()\n",
    "    cam.r = rotationMatrixToEulerAngles(Rresult)\n",
    "    cam.t = tresult\n",
    "\n",
    "def align(radarPoints, cameraPoints):\n",
    "    i = 0\n",
    "    while len(cameraPoints) != len(radarPoints):\n",
    "        cameraPoints = np.vstack((cameraPoints, cameraPoints[i%len(cameraPoints)]))\n",
    "        print(cameraPoints)\n",
    "        i+=1\n",
    "    ppoints = np.matrix(cameraPoints.T)\n",
    "    cpoints = np.matrix(radarPoints.T)\n",
    "    R, T, newcPoints = ICP_matching(ppoints, cpoints)\n",
    "    setupNewRT(R, T)\n",
    "    return R, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed 4 files. Rows:  21836  empty files number: 0\n",
      "empty files list: [  ]\n",
      "\n",
      "parsed 4 files. Rows:  2415  empty files number: 0\n",
      "empty files list: [  ]\n",
      "\n",
      "272\n",
      "275\n",
      "270\n",
      "[825 580]\n",
      "[411 291]\n",
      "[820.8209701 606.8656907]\n",
      "[412 303]\n",
      "[887 575]\n",
      "[443. 289.]\n",
      "[867.3956395 598.2005052]\n",
      "[434. 300.]\n",
      "[1138  625]\n",
      "[568. 313.]\n",
      "[1119.16348567  687.60567028]\n",
      "[561. 345.]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "import datetime\n",
    "\n",
    "# Change this to where data is stored\n",
    "radar_data_dir = os.path.join(data_dir, 'radar_detections')\n",
    "\n",
    "# Change this to where data is stored\n",
    "video_dir = data_dir\n",
    "\n",
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "topLeftCornerOfText    = (10,20)\n",
    "fontScale              = 0.5\n",
    "fontColor              = (0,0,0)\n",
    "lineType               = 2\n",
    "diffPosition           = 25\n",
    "\n",
    "# UI sliders callback functions\n",
    "def showText(frame):\n",
    "    cv2.putText(frame, \"x: \" + str(round(cam.t[0], 3)) + \" m\", \n",
    "    topLeftCornerOfText, \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    lineType)\n",
    "    cv2.putText(frame, \"y: \" + str(round(cam.t[1], 3)) + \" m\", \n",
    "    (topLeftCornerOfText[0], topLeftCornerOfText[1]+1*diffPosition), \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    lineType)\n",
    "    cv2.putText(frame, \"z: \" + str(round(cam.t[2], 3)) + \" m\", \n",
    "    (topLeftCornerOfText[0], topLeftCornerOfText[1]+2*diffPosition), \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    lineType)\n",
    "    cv2.putText(frame, \"Rx: \" + str(round(cam.r[0], 3)) + \" m\", \n",
    "    (topLeftCornerOfText[0], topLeftCornerOfText[1]+3*diffPosition), \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    lineType)\n",
    "    cv2.putText(frame, \"Ry: \" + str(round(cam.r[1], 3)) + \" m\", \n",
    "    (topLeftCornerOfText[0], topLeftCornerOfText[1]+4*diffPosition), \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    lineType)\n",
    "    cv2.putText(frame, \"Rz: \" + str(round(cam.r[2], 3)) + \" m\", \n",
    "    (topLeftCornerOfText[0], topLeftCornerOfText[1]+5*diffPosition), \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    lineType)\n",
    "\n",
    "def changeTX(x):\n",
    "    cam.t[0] = -(x - 10000)/1000.0\n",
    "    \n",
    "def changeTY(y):\n",
    "    cam.t[1] = -(y - 10000)/1000.0\n",
    "    \n",
    "def changeTZ(z):\n",
    "    cam.t[2] = -(z - 10000)/1000.0\n",
    "    \n",
    "def changeRX(x):\n",
    "    cam.r[0] = (x - 10000)/1000.0/100.0\n",
    "    \n",
    "def changeRY(y):\n",
    "    cam.r[1] = (y - 10000)/1000.0/100.0\n",
    "    \n",
    "def changeRZ(z):\n",
    "    cam.r[2] = (z - 10000)/1000.0/100.0\n",
    "\n",
    "def rescale_frame(frame, percent=75):\n",
    "    width = int(frame.shape[1] * percent/ 100)\n",
    "    height = int(frame.shape[0] * percent/ 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)\n",
    "\n",
    "# Reading a single tsv file by path\n",
    "def read_table(path):\n",
    "    try:\n",
    "        return pd.read_csv(path, delimiter='\\t', skiprows=[1])\n",
    "    except pd.errors.EmptyDataError as ede:\n",
    "        return []\n",
    "\n",
    "# Reading all tsv files in a folder\n",
    "def read_tables(folder):\n",
    "    \"\"\"reads all tables found in directory and concatenates them into one big\n",
    "    table\n",
    "    \"\"\"\n",
    "    common_table = pd.DataFrame()\n",
    "    empty_files = []\n",
    "    nparsed = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for f in [f for f in sorted(files) if os.path.splitext(f)[-1] == '.tsv']:\n",
    "            # print('scanning file', f, '...', end=' ')\n",
    "            try:\n",
    "                # Основной вызов в чтении. delimiter='\\t', чтобы считать табы разделителями,\n",
    "                # skiprows=[1], чтобы пропустить строку с типами данных.\n",
    "                table = pd.read_csv(os.path.join(root, f), delimiter='\\t', skiprows=[1])\n",
    "            except pd.errors.EmptyDataError as ede:\n",
    "                # print('Empty file!!')\n",
    "                empty_files.append(f)\n",
    "            finally:\n",
    "                # print(table.shape)\n",
    "                common_table = common_table.append(table)\n",
    "\n",
    "            nparsed += 1\n",
    "\n",
    "    print('parsed', nparsed, 'files. Rows: ', common_table.shape[0], ' empty files number:', len(empty_files))\n",
    "    print('empty files list: [', ', '.join(empty_files), ']\\n')\n",
    "    \n",
    "    # чтобы установить сквозную нумерацию во всех прочитанных таблицах\n",
    "    common_table = common_table.reset_index(drop=True)\n",
    "    \n",
    "    return common_table\n",
    "\n",
    "def saveToFile(points):\n",
    "    np.savetxt('TestPoints'+str(datetime.datetime.now()), points, delimiter=',')\n",
    "\n",
    "def drawPoints(drawPoints, frame_todraw, size = 5, color = (0, 0, 0)):\n",
    "    for point in drawPoints:\n",
    "        x, y = int(point[0]*0.5), int(point[1]*0.5)\n",
    "        if x < frame_todraw.shape[1] and y < frame_todraw.shape[0] and x > 0 and y > 0:\n",
    "            cv2.circle(frame_todraw, (x, y), size, color, -1)\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def closest_node(node, nodes):\n",
    "    return nodes[cdist([np.array([node[0]*2, node[1]*2])], nodes).argmin()]\n",
    "\n",
    "relatedPoints = np.array([])\n",
    "cartesianCameraPoints = np.array([])\n",
    "points = np.array([])\n",
    "settingRelation = False\n",
    "def setupRelation(event, x, y, flags, param):\n",
    "    global relatedPoints, settingRelation, cartesianCameraPoints, points\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if len(relatedPoints) == 0:\n",
    "            relatedPoints = np.array([[x, y]])\n",
    "        else:\n",
    "            relatedPoints = np.vstack((relatedPoints, [x, y]))\n",
    "        settingRelation = True\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        relatedPoints = np.vstack((relatedPoints, [x, y]))\n",
    "        # Check both buttons are present in\n",
    "#         threeDRadar = np.array([relatives[1][0], relatives[1][1], 0]) \n",
    "#         threeDCamera = np.array([relatives[0][0], relatives[0][1], 0])\n",
    "        \n",
    "        closestCameraPoint = closest_node(relatedPoints[-2], cartesianCameraPoints)\n",
    "        print(closestCameraPoint)\n",
    "        print(relatedPoints[-2])\n",
    "        closestRadarPoint = closest_node(relatedPoints[-1], points)\n",
    "        print(closestRadarPoint)\n",
    "        print(relatedPoints[-1])\n",
    "        relatedPoints = relatedPoints[:-2]\n",
    "        relatedPoints = np.vstack((relatedPoints, closestCameraPoint, closestRadarPoint))\n",
    "        \n",
    "        \n",
    "#         if (threeDCamera in cartesianCameraPoints and threeDRadar in points) or (threeDRadar in cartesianCameraPoints and threeDCamera in points):\n",
    "#              drawPoints(points, frame_todraw, color = (0,255,255))\n",
    "        settingRelation = False\n",
    "    elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "        relatedPoints = relatedPoints[:-1]\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # table = read_table(os.path.join(radar_data_dir, 't24.305.028.tsv')) # Reading t24.305.028.tsv radar points only\n",
    "    table = read_tables(radar_data_dir) # Reading all points # TODO: Fix reading data\n",
    "    selectedDataTable = table.iloc[:, [1, 3, 4]]\n",
    "    uniqueDataTable = selectedDataTable.grabMsec.unique()\n",
    "    \n",
    "    # Read camera detections\n",
    "    camera_data_dir = os.path.join(data_dir, 'camera_detections')\n",
    "    \n",
    "    # camera_table = read_table(os.path.join(camera_data_dir, 't24.305.028.left.avi.tsv'))\n",
    "    camera_table = read_tables(camera_data_dir)\n",
    "    selectedCameraDataTable = camera_table.iloc[:, [2, 4, 5, 6, 7]]\n",
    "    totalFrameNumber = 0 \n",
    "    isFirstZero = False\n",
    "    for index, row in selectedCameraDataTable.iterrows():\n",
    "#         print(row)\n",
    "        if row['FrameNumber'] == 0:\n",
    "            if isFirstZero:\n",
    "                print(currentValue)\n",
    "                totalFrameNumber += currentValue\n",
    "                isFirstZero = False\n",
    "        elif not isFirstZero:\n",
    "            isFirstZero = True    \n",
    "        currentValue = row['FrameNumber']\n",
    "        selectedCameraDataTable.at[index, 'FrameNumber'] = totalFrameNumber + currentValue\n",
    "        selectedCameraDataTable.at[index, 'x'] = row['x'] + 0.5*row['w']\n",
    "        selectedCameraDataTable.at[index, 'y'] = row['y'] + 0.5*row['h']\n",
    "    \n",
    "    cap = cv2.VideoCapture(os.path.join(video_dir, 't24.305.026-029.left.mov'))\n",
    "    # Creating UI\n",
    "    cv2.namedWindow('frame')\n",
    "    cv2.createTrackbar('t_x', 'frame', 10159, 20000, changeTX)\n",
    "    cv2.createTrackbar('t_y', 'frame', 8420, 20000, changeTY)\n",
    "    cv2.createTrackbar('t_z', 'frame', 11257, 20000, changeTZ)\n",
    "    cv2.createTrackbar('r_x', 'frame', 14164, 20000, changeRX)\n",
    "    cv2.createTrackbar('r_y', 'frame', 7388, 20000, changeRY)\n",
    "    cv2.createTrackbar('r_z', 'frame', 7797, 20000, changeRZ)\n",
    "    \n",
    "    cv2.setMouseCallback('frame', setupRelation)\n",
    "    \n",
    "    pause = False\n",
    "    # Change to what suits your system more\n",
    "    key_space = 32\n",
    "    \n",
    "    # Current index of an element from yml.gz's grabmsec list\n",
    "    grabmsecsIndex = 0\n",
    "    # Current index of an element from radar tsv's grabmsec list\n",
    "    radarDetectionsIndex = 0\n",
    "    frame = None\n",
    "    newRadarPoints = None\n",
    "    while(True):\n",
    "        if not pause:\n",
    "            ret, frame = cap.read()\n",
    "            newRadarPoints = None\n",
    "            relatedPoints = np.array([])\n",
    "            settingRelation = False\n",
    "            # Checking ret causes video to stop in the end\n",
    "            #if ret is False:\n",
    "            #    break\n",
    "            \n",
    "        if frame is None: # Loop video\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            grabmsecsIndex = 0\n",
    "            radarDetectionsIndex = 0\n",
    "            continue\n",
    "        if not pause:\n",
    "            frame = rescale_frame(frame, percent=50)\n",
    "        if grabmsecsIndex >= len(grabmsecs):\n",
    "            # There are no more frames to show\n",
    "            continue\n",
    "            \n",
    "        # Calculate the radar grabmsec index closest to the camera grabmsec index\n",
    "        while radarDetectionsIndex + 1 < len(uniqueDataTable) and uniqueDataTable[radarDetectionsIndex + 1] < grabmsecs[grabmsecsIndex]:\n",
    "            radarDetectionsIndex += 1\n",
    "            \n",
    "        if radarDetectionsIndex+1 >= len(uniqueDataTable):\n",
    "            # There are no more radar detections to show. \n",
    "            grabmsecsIndex += 1\n",
    "            # Show frame without any detections and continue\n",
    "            cv2.imshow('frame', frame)\n",
    "            continue\n",
    "        # Get current grabmsecs of both camera and radar\n",
    "        currentGrabmsec = grabmsecs[grabmsecsIndex]\n",
    "        \n",
    "        currentFrameDetections = selectedDataTable.loc[selectedDataTable['grabMsec'] == uniqueDataTable[radarDetectionsIndex]]\n",
    "        cartesianPoints = convertToCartesian(currentFrameDetections.values[:,-2:])\n",
    "        points = cam.project(cartesianPoints)\n",
    "        \n",
    "        # Camera detections\n",
    "        # WARNING: FRAME NUMBER IS THE SAME IN ALL FILES 026, 027, 028 avi tsv\n",
    "        currentFrameCameraDetections = selectedCameraDataTable.loc[selectedCameraDataTable['FrameNumber'] == grabmsecsIndex]\n",
    "        currentFrameCameraDetectionsValues = currentFrameCameraDetections.values[:, -4:-2]\n",
    "        cartesianCameraPoints = currentFrameCameraDetectionsValues # np.array(list(map(lambda x: np.array([x[0], x[1], 0]), currentFrameCameraDetectionsValues)))\n",
    "        frame_todraw = frame.copy() #don't draw on original frame\n",
    "        \n",
    "        drawPoints(gridPoints, frame_todraw, 2, (0, 0, 0))\n",
    "        drawPoints(points, frame_todraw, color = (0,255,0))\n",
    "        drawPoints(cartesianCameraPoints, frame_todraw, color = (193,0,32))\n",
    "        if newRadarPoints is not None:\n",
    "            drawPoints(newRadarPoints, frame_todraw, color = (255,255,0))\n",
    "            \n",
    "        if len(relatedPoints) > 0 and not settingRelation:\n",
    "            firstPoints = relatedPoints[0::2]\n",
    "            secondPoints = relatedPoints[1::2]\n",
    "            for relatives in zip(firstPoints, secondPoints):\n",
    "                cv2.line(frame_todraw, (int(0.5*relatives[0][0]), int(0.5*relatives[0][1])), (int(0.5*relatives[1][0]), int(0.5*relatives[1][1])), (0, 255, 255), thickness=1, lineType=8)\n",
    "                drawPoints([relatives[0]], frame_todraw, color = (0,255,255))\n",
    "                drawPoints([relatives[1]], frame_todraw, color = (0,127,127))\n",
    "        showText(frame_todraw)\n",
    "        # Show frame with detections\n",
    "        cv2.imshow('frame', frame_todraw)\n",
    "        \n",
    "        if not pause:\n",
    "            # Go to the next camera grabmsec value\n",
    "            grabmsecsIndex += 1\n",
    "        # Checking if the user pressed q key to exit the video\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'): # Press 'Q' key to exit\n",
    "            break\n",
    "        if key == ord('s'):\n",
    "            if relatedPoints is not None:\n",
    "                saveToFile(relatedPoints)\n",
    "        if key == ord('a'):\n",
    "            R, t = align(relatedPoints[1::2], relatedPoints[0::2])\n",
    "            #points, currentFrameCameraDetectionsValues\n",
    "            newRadarPoints = np.array((R * np.matrix(points.T) + t).T)\n",
    "            drawPoints(newRadarPoints, frame_todraw, color = (255,0,0))\n",
    "            print(points)\n",
    "            print(newRadarPoints)\n",
    "            cv2.imshow('frame', frame_todraw)\n",
    "        if key == key_space:\n",
    "            pause = not pause\n",
    "            \n",
    "        \n",
    "            \n",
    "    # Destroing the video window\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPoints():\n",
    "    relatedPoints = np.loadtxt(\"TestPoints2018-10-08 23/46/50.838083\") # Insert points\n",
    "    align(relatedPoints[1::2], relatedPoints[0::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!python Radar_detections_script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camera_radar",
   "language": "python",
   "name": "camera_radar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
